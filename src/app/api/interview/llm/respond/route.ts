import { streamText } from "ai";
import { openaiProvider, getModel } from "@/core/ai/provider";

export async function POST(req: Request) {
  try {
    const { transcript, context } = await req.json();

    const prompt = `
VocÃª Ã© uma entrevistadora de RH comportamental e tÃ©cnica.
Seu papel Ã© conduzir entrevistas humanas, naturais e empÃ¡ticas.
Baseie-se no contexto abaixo e gere uma resposta breve, em tom de conversa.
Se o candidato parecer nervoso ou fugir do assunto, encoraje-o gentilmente.

ğŸ“‹ Contexto da vaga:
Cargo: ${context?.jobTitle ?? "vaga nÃ£o informada"}
Nome do candidato: ${context?.candidateName ?? "Candidato"}
Resposta do candidato: "${transcript}"

ğŸ¯ Gere a prÃ³xima fala da IA (em portuguÃªs, tom natural e amigÃ¡vel):
`;

    // âœ… modelo configurado corretamente
    const result = await streamText({
      model: openaiProvider(getModel("llm")),
      prompt,
      temperature: 0.8,
      maxOutputTokens: 200,
    });

    return result.toTextStreamResponse({
      headers: {
        "Content-Type": "text/plain; charset=utf-8",
      },
    });
  } catch (err) {
    console.error("âŒ LLM error:", err);
    return new Response("Erro ao gerar resposta", { status: 500 });
  }
}
